# ÂÆûÁé∞ÊåáÂçóÔºöÊûÑÂª∫ Node.js ‰ª£ÁêÜ

## ÂÆûÁé∞Ê¶ÇËø∞

Êú¨Á´†Êèê‰æõÂü∫‰∫é Node.js ÁöÑËá™Âª∫‰ª£ÁêÜÔºàProxyÔºâÂÆåÊï¥ÂÆûÁé∞ÊñπÊ°àÔºåÁõÆÊ†áÊòØÔºö

- üîÑ **ÂçèËÆÆÊ°•Êé•**ÔºöÊîØÊåÅ Chat ‚Üî Responses ÂèåÂêëËΩ¨Êç¢
- üöÄ **ÊµÅÂºèÂ§ÑÁêÜ**ÔºöÂÆåÊï¥ÁöÑ SSE ‰∫ã‰ª∂ÊµÅËΩ¨Âèë‰∏éÂêàÊàê
- üåê **Â§öÂéÇÂïÜÊîØÊåÅ**ÔºöÂèØÊâ©Â±ïËá≥ÂêÑÁßç‰∏äÊ∏∏ LLM ÊúçÂä°
- üõ†Ô∏è **Áîü‰∫ßÂ∞±Áª™**ÔºöÂåÖÂê´ÈîôËØØÂ§ÑÁêÜ„ÄÅÁõëÊéß„ÄÅÈÉ®ÁΩ≤ÊñπÊ°à

### ÂÆûÁé∞Á≠ñÁï•ÈÄâÊã©

| ÂÆûÁé∞Ê®°Âºè | ÈÄÇÁî®Âú∫ÊôØ | Â§çÊùÇÂ∫¶ | Êé®ËçêÂ∫¶ |
|----------|----------|--------|--------|
| **Chat Áõ¥ÈÄö** | ‰∏äÊ∏∏ÊîØÊåÅ Chat API | ‰Ωé | ‚≠ê‚≠ê‚≠ê È¶ñÈÄâ |
| **Responses Áõ¥ÈÄö** | ‰∏äÊ∏∏ÊîØÊåÅ Responses API | ‰Ωé | ‚≠ê‚≠ê Â¶ÇÊûúÂèØÁî® |
| **Chat ‚Üí Responses Ê°•Êé•** | ÈúÄË¶ÅÂÆåÊï¥ËØ≠‰πâÊîØÊåÅ | ‰∏≠ | ‚≠ê‚≠ê ÊåâÈúÄÂÆûÁé∞ |

## ÊäÄÊúØÊ†à‰∏é‰æùËµñ

### ËøêË°åÊó∂ÁéØÂ¢É

```json
{
  "engines": {
    "node": ">=18.0.0"
  },
  "type": "module"
}
```

**Ê†∏ÂøÉÁâπÊÄß**Ôºö
- **ÂÜÖÁΩÆ fetch**ÔºöNode 18+ ÂéüÁîüÊîØÊåÅ
- **Web Streams**ÔºöÊµÅÂºèÂ§ÑÁêÜÊ†áÂáÜ API
- **ES Modules**ÔºöÁé∞‰ª£Ê®°ÂùóÁ≥ªÁªü

### È°πÁõÆ‰æùËµñ

```json
{
  "dependencies": {
    "express": "^4.19.2",      // Web Ê°ÜÊû∂
    "cors": "^2.8.5",          // CORS ÊîØÊåÅ
    "helmet": "^7.1.0",        // ÂÆâÂÖ®Â§¥
    "pino": "^8.17.0",         // È´òÊÄßËÉΩÊó•Âøó
    "undici": "^6.6.0"         // ÂèØÈÄâÔºöÈ´òÊÄßËÉΩ HTTP ÂÆ¢Êà∑Á´Ø
  },
  "devDependencies": {
    "tsx": "^4.7.0",           // TypeScript ÊâßË°åÂô®
    "typescript": "^5.4.0",    // TypeScript ÁºñËØëÂô®
    "@types/express": "^4.17.21",
    "@types/cors": "^2.8.17"
  }
}
```

### ÂºÄÂèëÂ∑•ÂÖ∑Èìæ

```json
{
  "scripts": {
    "dev": "tsx watch src/server.ts",
    "build": "tsc && npm run copy-assets",
    "start": "node dist/server.js",
    "test": "tsx test/integration.test.ts",
    "copy-assets": "cp -r src/static dist/"
  }
}
```

## È°πÁõÆÁªìÊûÑËÆæËÆ°

```
codex-proxy/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ server.ts              # ÊúçÂä°Âô®ÂÖ•Âè£
‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat.ts           # Chat Completions Á´ØÁÇπ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ responses.ts      # Responses Á´ØÁÇπ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ health.ts         # ÂÅ•Â∫∑Ê£ÄÊü•
‚îÇ   ‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sse.ts           # SSE Â∑•ÂÖ∑ÂáΩÊï∞
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.ts        # ÈÖçÁΩÆÁÆ°ÁêÜ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logger.ts        # Êó•ÂøóÁ≥ªÁªü
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ validation.ts    # ËØ∑Ê±ÇÈ™åËØÅ
‚îÇ   ‚îú‚îÄ‚îÄ transform/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat-to-responses.ts    # Chat ‚Üí Responses ËΩ¨Êç¢
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ responses-to-chat.ts    # Responses ‚Üí Chat ËΩ¨Êç¢
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tools-mapping.ts       # Â∑•ÂÖ∑Ë∞ÉÁî®Êò†Â∞Ñ
‚îÇ   ‚îú‚îÄ‚îÄ middleware/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.ts          # Èâ¥ÊùÉ‰∏≠Èó¥‰ª∂
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rate-limit.ts    # ÈôêÊµÅ‰∏≠Èó¥‰ª∂
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ error-handler.ts # ÈîôËØØÂ§ÑÁêÜ
‚îÇ   ‚îî‚îÄ‚îÄ types/
‚îÇ       ‚îú‚îÄ‚îÄ openai.ts        # OpenAI API Á±ªÂûã
‚îÇ       ‚îî‚îÄ‚îÄ codex.ts         # Codex ÂÜÖÈÉ®Á±ªÂûã
‚îú‚îÄ‚îÄ test/
‚îÇ   ‚îú‚îÄ‚îÄ integration/         # ÈõÜÊàêÊµãËØï
‚îÇ   ‚îú‚îÄ‚îÄ fixtures/           # ÊµãËØïÊï∞ÊçÆ
‚îÇ   ‚îî‚îÄ‚îÄ mocks/              # Mock ÊúçÂä°
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ development.toml    # ÂºÄÂèëÈÖçÁΩÆ
‚îÇ   ‚îú‚îÄ‚îÄ production.toml     # Áîü‰∫ßÈÖçÁΩÆ
‚îÇ   ‚îî‚îÄ‚îÄ local.toml.example  # ÈÖçÁΩÆÊ®°Êùø
‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile          # ÂÆπÂô®ÈïúÂÉè
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml  # Êú¨Âú∞ÂºÄÂèëÁéØÂ¢É
‚îî‚îÄ‚îÄ docs/
    ‚îú‚îÄ‚îÄ api.md              # API ÊñáÊ°£
    ‚îî‚îÄ‚îÄ deployment.md       # ÈÉ®ÁΩ≤ÊåáÂçó
```

## Ê†∏ÂøÉÂÆûÁé∞

### ÊúçÂä°Âô®ÂÖ•Âè£

```typescript
// src/server.ts
import express from 'express';
import cors from 'cors';
import helmet from 'helmet';
import pino from 'pino';

import { loadConfig } from './lib/config.js';
import { createLogger } from './lib/logger.js';
import { authMiddleware } from './middleware/auth.js';
import { rateLimitMiddleware } from './middleware/rate-limit.js';
import { errorHandler } from './middleware/error-handler.js';

import chatRoutes from './routes/chat.js';
import responsesRoutes from './routes/responses.js';
import healthRoutes from './routes/health.js';

async function createServer() {
  const config = await loadConfig();
  const logger = createLogger(config.log);
  const app = express();

  // ÂÆâÂÖ®ÂíåÂü∫Á°Ä‰∏≠Èó¥‰ª∂
  app.use(helmet());
  app.use(cors({
    origin: config.cors.allowedOrigins,
    credentials: true
  }));
  
  // ËØ∑Ê±ÇËß£Êûê
  app.use(express.json({ 
    limit: config.server.maxRequestSize 
  }));

  // Ëá™ÂÆö‰πâ‰∏≠Èó¥‰ª∂
  app.use(authMiddleware(config.auth));
  app.use(rateLimitMiddleware(config.rateLimit));

  // Ë∑ØÁî±Ê≥®ÂÜå
  app.use('/v1/chat', chatRoutes);
  app.use('/v1/responses', responsesRoutes);
  app.use('/health', healthRoutes);

  // ÈîôËØØÂ§ÑÁêÜÔºàÂøÖÈ°ªÂú®ÊúÄÂêéÔºâ
  app.use(errorHandler(logger));

  return { app, logger, config };
}

async function main() {
  const { app, logger, config } = await createServer();
  
  const server = app.listen(config.server.port, () => {
    logger.info(
      `Codex Proxy listening on port ${config.server.port}`,
      { 
        environment: config.environment,
        upstreamUrl: config.upstream.baseUrl
      }
    );
  });

  // ‰ºòÈõÖÂÖ≥Èó≠
  process.on('SIGTERM', () => {
    logger.info('SIGTERM received, shutting down gracefully');
    server.close(() => {
      logger.info('Server closed');
      process.exit(0);
    });
  });
}

main().catch(console.error);
```

### ÈÖçÁΩÆÁÆ°ÁêÜ

```typescript
// src/lib/config.ts
export interface ProxyConfig {
  environment: 'development' | 'production' | 'test';
  server: {
    port: number;
    maxRequestSize: string;
    timeout: number;
  };
  upstream: {
    baseUrl: string;
    apiKey?: string;
    supportsResponses: boolean;
    timeout: number;
    retries: number;
  };
  cors: {
    allowedOrigins: string[];
  };
  rateLimit: {
    windowMs: number;
    maxRequests: number;
  };
  auth: {
    enabled: boolean;
    apiKeys: string[];
  };
  log: {
    level: string;
    format: 'json' | 'pretty';
  };
}

export async function loadConfig(): Promise<ProxyConfig> {
  const environment = process.env.NODE_ENV || 'development';
  
  // Âü∫Á°ÄÈÖçÁΩÆ
  const config: ProxyConfig = {
    environment: environment as ProxyConfig['environment'],
    server: {
      port: parseInt(process.env.PORT || '3000'),
      maxRequestSize: process.env.MAX_REQUEST_SIZE || '10mb',
      timeout: parseInt(process.env.SERVER_TIMEOUT || '300000'),
    },
    upstream: {
      baseUrl: process.env.UPSTREAM_BASE_URL || 'https://api.openai.com/v1',
      apiKey: process.env.UPSTREAM_API_KEY,
      supportsResponses: process.env.UPSTREAM_SUPPORTS_RESPONSES === 'true',
      timeout: parseInt(process.env.UPSTREAM_TIMEOUT || '300000'),
      retries: parseInt(process.env.UPSTREAM_RETRIES || '3'),
    },
    cors: {
      allowedOrigins: process.env.CORS_ORIGINS?.split(',') || ['*'],
    },
    rateLimit: {
      windowMs: parseInt(process.env.RATE_LIMIT_WINDOW || '60000'),
      maxRequests: parseInt(process.env.RATE_LIMIT_MAX || '100'),
    },
    auth: {
      enabled: process.env.AUTH_ENABLED === 'true',
      apiKeys: process.env.API_KEYS?.split(',') || [],
    },
    log: {
      level: process.env.LOG_LEVEL || 'info',
      format: (process.env.LOG_FORMAT as 'json' | 'pretty') || 'json',
    },
  };

  // ÈÖçÁΩÆÈ™åËØÅ
  validateConfig(config);
  
  return config;
}

function validateConfig(config: ProxyConfig): void {
  if (!config.upstream.baseUrl) {
    throw new Error('UPSTREAM_BASE_URL is required');
  }
  
  if (config.auth.enabled && config.auth.apiKeys.length === 0) {
    throw new Error('API_KEYS required when AUTH_ENABLED=true');
  }
  
  // Êõ¥Â§öÈ™åËØÅÈÄªËæë...
}
```

### SSE Â∑•ÂÖ∑Â∫ì

```typescript
// src/lib/sse.ts
import { Response } from 'express';

export class SSEWriter {
  private response: Response;
  private isConnected = true;

  constructor(response: Response) {
    this.response = response;
    this.setupSSE();
    this.setupErrorHandlers();
  }

  private setupSSE(): void {
    this.response.writeHead(200, {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache', 
      'Connection': 'keep-alive',
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Headers': 'Cache-Control'
    });
  }

  private setupErrorHandlers(): void {
    this.response.on('close', () => {
      this.isConnected = false;
    });

    this.response.on('error', (err) => {
      console.error('SSE connection error:', err);
      this.isConnected = false;
    });
  }

  writeData(data: any): boolean {
    if (!this.isConnected) return false;
    
    try {
      this.response.write(`data: ${JSON.stringify(data)}\n\n`);
      return true;
    } catch (err) {
      console.error('Failed to write SSE data:', err);
      this.isConnected = false;
      return false;
    }
  }

  writeComment(comment: string): boolean {
    if (!this.isConnected) return false;
    
    try {
      this.response.write(`: ${comment}\n\n`);
      return true;
    } catch (err) {
      this.isConnected = false;
      return false;
    }
  }

  writeDone(): boolean {
    if (!this.isConnected) return false;
    
    try {
      this.response.write('data: [DONE]\n\n');
      return true;
    } catch (err) {
      this.isConnected = false;
      return false;
    }
  }

  end(): void {
    if (this.isConnected) {
      this.response.end();
      this.isConnected = false;
    }
  }

  get connected(): boolean {
    return this.isConnected;
  }
}

// ÂøÉË∑≥‰øùÊåÅËøûÊé•
export class SSEHeartbeat {
  private timer?: NodeJS.Timeout;
  private writer: SSEWriter;

  constructor(writer: SSEWriter, intervalMs: number = 30000) {
    this.writer = writer;
    this.start(intervalMs);
  }

  private start(intervalMs: number): void {
    this.timer = setInterval(() => {
      if (this.writer.connected) {
        this.writer.writeComment('heartbeat');
      } else {
        this.stop();
      }
    }, intervalMs);
  }

  stop(): void {
    if (this.timer) {
      clearInterval(this.timer);
      this.timer = undefined;
    }
  }
}
```

### Chat Completions Á´ØÁÇπ

```typescript
// src/routes/chat.ts
import { Router, Request, Response } from 'express';
import { ProxyConfig } from '../lib/config.js';
import { SSEWriter, SSEHeartbeat } from '../lib/sse.js';
import { Logger } from 'pino';

const router = Router();

interface ChatCompletionsRequest {
  model: string;
  messages: any[];
  stream?: boolean;
  tools?: any[];
  [key: string]: any;
}

router.post('/completions', async (req: Request, res: Response) => {
  const config = req.app.get('config') as ProxyConfig;
  const logger = req.app.get('logger') as Logger;
  
  try {
    const requestBody = req.body as ChatCompletionsRequest;
    
    // Âº∫Âà∂ÂêØÁî®ÊµÅÂºè
    requestBody.stream = true;
    
    // ÊûÑÂª∫‰∏äÊ∏∏ËØ∑Ê±Ç
    const upstreamUrl = new URL('/chat/completions', config.upstream.baseUrl);
    
    // Azure ÁâπÊÆäÂ§ÑÁêÜ
    if (isAzureEndpoint(config.upstream.baseUrl)) {
      upstreamUrl.searchParams.set('api-version', '2025-04-01-preview');
    }

    const headers: Record<string, string> = {
      'Content-Type': 'application/json',
      'Accept': 'text/event-stream',
    };

    // Èâ¥ÊùÉÂ§¥
    if (config.upstream.apiKey) {
      headers['Authorization'] = `Bearer ${config.upstream.apiKey}`;
    }

    // ÂèëËµ∑‰∏äÊ∏∏ËØ∑Ê±Ç
    const upstreamResponse = await fetch(upstreamUrl, {
      method: 'POST',
      headers,
      body: JSON.stringify(requestBody),
      signal: AbortSignal.timeout(config.upstream.timeout)
    });

    // ÈîôËØØÂ§ÑÁêÜ
    if (!upstreamResponse.ok) {
      await handleUpstreamError(upstreamResponse, res, logger);
      return;
    }

    // ÊµÅÂºèËΩ¨Âèë
    await streamChatResponse(upstreamResponse, res, logger);
    
  } catch (error) {
    logger.error({ error: error.message }, 'Chat endpoint error');
    res.status(500).json({
      error: {
        message: 'Internal server error',
        type: 'server_error'
      }
    });
  }
});

async function streamChatResponse(
  upstreamResponse: globalThis.Response,
  res: Response,
  logger: Logger
): Promise<void> {
  const writer = new SSEWriter(res);
  const heartbeat = new SSEHeartbeat(writer);
  
  try {
    const reader = upstreamResponse.body!.getReader();
    const decoder = new TextDecoder();
    let buffer = '';

    while (writer.connected) {
      const { done, value } = await reader.read();
      if (done) break;

      buffer += decoder.decode(value, { stream: true });
      
      // Â§ÑÁêÜÂÆåÊï¥ÁöÑ SSE Âùó
      let newlineIndex;
      while ((newlineIndex = buffer.indexOf('\n\n')) !== -1) {
        const chunk = buffer.slice(0, newlineIndex).trim();
        buffer = buffer.slice(newlineIndex + 2);
        
        if (chunk.startsWith('data: ')) {
          const data = chunk.slice(6);
          
          if (data === '[DONE]') {
            writer.writeDone();
            break;
          }
          
          try {
            const parsed = JSON.parse(data);
            writer.writeData(parsed);
          } catch (err) {
            logger.warn({ data }, 'Failed to parse SSE data');
          }
        }
      }
    }
  } catch (error) {
    logger.error({ error: error.message }, 'Stream processing error');
  } finally {
    heartbeat.stop();
    writer.end();
  }
}

async function handleUpstreamError(
  upstreamResponse: globalThis.Response,
  res: Response,
  logger: Logger
): Promise<void> {
  const statusCode = upstreamResponse.status;
  const statusText = upstreamResponse.statusText;
  
  // ÈÄè‰º†ÈáçË¶ÅÂ§¥
  const retryAfter = upstreamResponse.headers.get('retry-after');
  if (retryAfter) {
    res.set('Retry-After', retryAfter);
  }

  try {
    const errorBody = await upstreamResponse.text();
    logger.warn(
      { statusCode, statusText, errorBody },
      'Upstream error response'
    );
    
    res.status(statusCode).json(
      errorBody ? JSON.parse(errorBody) : {
        error: {
          message: statusText,
          type: 'upstream_error'
        }
      }
    );
  } catch (err) {
    res.status(statusCode).json({
      error: {
        message: statusText,
        type: 'upstream_error'
      }
    });
  }
}

function isAzureEndpoint(baseUrl: string): boolean {
  return baseUrl.includes('.openai.azure.com');
}

export default router;
```

### Responses Á´ØÁÇπÂÆûÁé∞

```typescript
// src/routes/responses.ts
import { Router, Request, Response } from 'express';
import { SSEWriter, SSEHeartbeat } from '../lib/sse.js';
import { chatToResponsesTransform } from '../transform/chat-to-responses.js';

const router = Router();

router.post('/', async (req: Request, res: Response) => {
  const config = req.app.get('config');
  const logger = req.app.get('logger');

  try {
    if (config.upstream.supportsResponses) {
      // Áõ¥ÈÄöÊ®°ÂºèÔºö‰∏äÊ∏∏ÂéüÁîüÊîØÊåÅ Responses API
      await handleDirectResponsesMode(req, res, config, logger);
    } else {
      // Ê°•Êé•Ê®°ÂºèÔºöChat ‚Üí Responses ËΩ¨Êç¢
      await handleBridgeMode(req, res, config, logger);
    }
  } catch (error) {
    logger.error({ error: error.message }, 'Responses endpoint error');
    res.status(500).json({
      error: {
        message: 'Internal server error',
        type: 'server_error'
      }
    });
  }
});

// Áõ¥ÈÄöÊ®°ÂºèÔºö‰∏äÊ∏∏ÊîØÊåÅ Responses
async function handleDirectResponsesMode(
  req: Request,
  res: Response,
  config: any,
  logger: any
): Promise<void> {
  const upstreamUrl = new URL('/responses', config.upstream.baseUrl);
  
  const headers = {
    'Content-Type': 'application/json',
    'Accept': 'text/event-stream',
    'OpenAI-Beta': 'responses=experimental'
  };

  if (config.upstream.apiKey) {
    headers['Authorization'] = `Bearer ${config.upstream.apiKey}`;
  }

  const upstreamResponse = await fetch(upstreamUrl, {
    method: 'POST',
    headers,
    body: JSON.stringify(req.body),
    signal: AbortSignal.timeout(config.upstream.timeout)
  });

  if (!upstreamResponse.ok) {
    await handleUpstreamError(upstreamResponse, res, logger);
    return;
  }

  // Áõ¥Êé•ËΩ¨Âèë SSE ÊµÅ
  const writer = new SSEWriter(res);
  const heartbeat = new SSEHeartbeat(writer);

  try {
    const reader = upstreamResponse.body!.getReader();
    
    while (writer.connected) {
      const { done, value } = await reader.read();
      if (done) break;
      
      res.write(Buffer.from(value));
    }
  } finally {
    heartbeat.stop();
    writer.end();
  }
}

// Ê°•Êé•Ê®°ÂºèÔºöChat ‚Üí Responses ËΩ¨Êç¢
async function handleBridgeMode(
  req: Request,
  res: Response,
  config: any,
  logger: any
): Promise<void> {
  // 1. Â∞Ü Responses ËØ∑Ê±ÇËΩ¨Êç¢‰∏∫ Chat ËØ∑Ê±Ç
  const chatRequest = responsesToChatRequest(req.body);
  
  // 2. Ë∞ÉÁî®‰∏äÊ∏∏ Chat API
  const upstreamUrl = new URL('/chat/completions', config.upstream.baseUrl);
  
  const headers = {
    'Content-Type': 'application/json',
    'Accept': 'text/event-stream'
  };

  if (config.upstream.apiKey) {
    headers['Authorization'] = `Bearer ${config.upstream.apiKey}`;
  }

  const upstreamResponse = await fetch(upstreamUrl, {
    method: 'POST',
    headers,
    body: JSON.stringify(chatRequest),
    signal: AbortSignal.timeout(config.upstream.timeout)
  });

  if (!upstreamResponse.ok) {
    await handleUpstreamError(upstreamResponse, res, logger);
    return;
  }

  // 3. Â∞Ü Chat ÊµÅËΩ¨Êç¢‰∏∫ Responses ‰∫ã‰ª∂
  const writer = new SSEWriter(res);
  const heartbeat = new SSEHeartbeat(writer);

  try {
    await chatToResponsesTransform(upstreamResponse, writer, logger);
  } finally {
    heartbeat.stop();
    writer.end();
  }
}

// ÁÆÄÂåñÁâà Responses ‚Üí Chat ËΩ¨Êç¢
function responsesToChatRequest(responsesBody: any): any {
  const { model, instructions, input, tools } = responsesBody;

  // ÊûÑÂª∫ messages Êï∞ÁªÑ
  const messages: any[] = [];
  
  // Á≥ªÁªüÊåá‰ª§
  if (instructions) {
    messages.push({ role: 'system', content: instructions });
  }

  // Â§ÑÁêÜËæìÂÖ•ÂéÜÂè≤ÔºàÁÆÄÂåñÁâàÔºå‰ªÖÂ§ÑÁêÜÊñáÊú¨Ê∂àÊÅØÔºâ
  if (Array.isArray(input)) {
    for (const item of input) {
      if (item?.type === 'message') {
        const content = extractTextContent(item.content);
        if (content) {
          messages.push({ 
            role: item.role || 'user', 
            content 
          });
        }
      }
      // TODO: Â§ÑÁêÜÂ∑•ÂÖ∑Ë∞ÉÁî®ËæìÂá∫Á≠âÂ§çÊùÇÊÉÖÂÜµ
    }
  }

  return {
    model,
    messages,
    stream: true,
    tools: convertTooChatTools(tools)  // ËΩ¨Êç¢Â∑•ÂÖ∑Ê†ºÂºè
  };
}

function extractTextContent(content: any[]): string {
  if (!Array.isArray(content)) return '';
  
  return content
    .filter(c => c?.type === 'input_text' || c?.type === 'output_text')
    .map(c => c.text || '')
    .join('');
}

function convertTooChatTools(responsesTools: any[]): any[] {
  if (!Array.isArray(responsesTools)) return [];
  
  // Âè™‰øùÁïô function Á±ªÂûãÂ∑•ÂÖ∑
  return responsesTools
    .filter(tool => tool?.type === 'function')
    .map(tool => ({
      type: 'function',
      function: {
        name: tool.name,
        description: tool.description,
        parameters: tool.parameters
      }
    }));
}

export default router;
```

### Chat ‚Üí Responses ‰∫ã‰ª∂ËΩ¨Êç¢

```typescript
// src/transform/chat-to-responses.ts
import { SSEWriter } from '../lib/sse.js';

interface FunctionCallState {
  id?: string;
  name?: string;
  arguments: string;
}

export async function chatToResponsesTransform(
  upstreamResponse: globalThis.Response,
  writer: SSEWriter,
  logger: any
): Promise<void> {
  const reader = upstreamResponse.body!.getReader();
  const decoder = new TextDecoder();
  
  let buffer = '';
  let responseId = '';
  let assistantText = '';
  
  // Â∑•ÂÖ∑Ë∞ÉÁî®Áä∂ÊÄÅÔºàÊîØÊåÅÂπ∂ÂèëË∞ÉÁî®Ôºâ
  const functionCalls = new Map<number, FunctionCallState>();

  try {
    while (writer.connected) {
      const { done, value } = await reader.read();
      if (done) break;

      buffer += decoder.decode(value, { stream: true });

      let newlineIndex;
      while ((newlineIndex = buffer.indexOf('\n\n')) !== -1) {
        const chunk = buffer.slice(0, newlineIndex).trim();
        buffer = buffer.slice(newlineIndex + 2);

        if (!chunk.startsWith('data: ')) continue;
        
        const data = chunk.slice(6).trim();
        
        if (data === '[DONE]') {
          // ÂÖúÂ∫ïÂÆåÊàê‰∫ã‰ª∂
          writer.writeData({
            type: 'response.completed',
            id: responseId || generateResponseId()
          });
          return;
        }

        try {
          const json = JSON.parse(data);
          responseId = json?.id || responseId;
          
          const choice = json?.choices?.[0];
          if (!choice) continue;

          const delta = choice.delta;
          const finishReason = choice.finish_reason;

          // Â§ÑÁêÜÊñáÊú¨Â¢ûÈáè
          if (delta?.content) {
            assistantText += delta.content;
            writer.writeData({
              type: 'response.output_text.delta',
              delta: delta.content
            });
          }

          // Â§ÑÁêÜÂ∑•ÂÖ∑Ë∞ÉÁî®Â¢ûÈáè
          if (delta?.tool_calls) {
            procesToolCallselta(delta.tool_calls, functionCalls);
          }

          // Â§ÑÁêÜÂÆåÊàêËØ≠‰πâ
          if (finishReason === 'tool_calls') {
            // ËæìÂá∫ÊâÄÊúâËÅöÂêàÁöÑÂ∑•ÂÖ∑Ë∞ÉÁî®
            for (const [, state] of functionCalls) {
              writer.writeData({
                type: 'response.output_item.done',
                item: {
                  type: 'function_call',
                  name: state.name || '',
                  arguments: state.arguments,
                  call_id: state.id || generateCallId()
                }
              });
            }

            // ÂÆåÊàê‰∫ã‰ª∂
            writer.writeData({
              type: 'response.completed',
              id: responseId
            });
            return;
          }

          if (finishReason === 'stop') {
            // ËæìÂá∫ÊúÄÁªàÁöÑ assistant Ê∂àÊÅØ
            if (assistantText) {
              writer.writeData({
                type: 'response.output_item.done',
                item: {
                  type: 'message',
                  role: 'assistant',
                  content: [
                    {
                      type: 'output_text',
                      text: assistantText
                    }
                  ]
                }
              });
            }

            // ÂÆåÊàê‰∫ã‰ª∂
            writer.writeData({
              type: 'response.completed',
              id: responseId
            });
            return;
          }
        } catch (err) {
          logger.warn({ data, error: err.message }, 'Failed to parse Chat SSE data');
        }
      }
    }
  } catch (error) {
    logger.error({ error: error.message }, 'Chat to Responses transform error');
    
    // ÂèëÈÄÅÈîôËØØ‰∫ã‰ª∂
    writer.writeData({
      type: 'response.failed',
      error: {
        message: 'Transform failed',
        type: 'transform_error'
      }
    });
  }
}

function procesToolCallselta(
  toolCalls: any[],
  functionCalls: Map<number, FunctionCallState>
): void {
  for (const toolCall of toolCalls) {
    const index = typeof toolCall.index === 'number' ? toolCall.index : 0;
    const state = functionCalls.get(index) || { arguments: '' };

    // Êõ¥Êñ∞Áä∂ÊÄÅ
    if (toolCall.id) {
      state.id = toolCall.id;
    }
    
    if (toolCall.function?.name) {
      state.name = toolCall.function.name;
    }
    
    if (toolCall.function?.arguments) {
      state.arguments += toolCall.function.arguments; // ÊãºÊé•ÂàÜÁâá
    }

    functionCalls.set(index, state);
  }
}

function generateResponseId(): string {
  return `resp_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
}

function generateCallId(): string {
  return `tc_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
}
```

## È´òÁ∫ßÁâπÊÄß

### ÈîôËØØÂ§ÑÁêÜ‰∏éÈáçËØï

```typescript
// src/lib/retry.ts
export interface RetryOptions {
  maxAttempts: number;
  baseDelayMs: number;
  maxDelayMs: number;
  backoffMultiplier: number;
}

export class RetryHandler {
  constructor(private options: RetryOptions) {}

  async execute<T>(
    operation: () => Promise<T>,
    shouldRetry: (error: any) => boolean = this.defaultShouldRetry
  ): Promise<T> {
    let lastError: any;

    for (let attempt = 1; attempt <= this.options.maxAttempts; attempt++) {
      try {
        return await operation();
      } catch (error) {
        lastError = error;

        if (attempt === this.options.maxAttempts || !shouldRetry(error)) {
          throw error;
        }

        const delay = this.calculateDelay(attempt);
        await this.delay(delay);
      }
    }

    throw lastError;
  }

  private calculateDelay(attempt: number): number {
    const exponentialDelay = this.options.baseDelayMs * 
      Math.pow(this.options.backoffMultiplier, attempt - 1);
    
    return Math.min(exponentialDelay, this.options.maxDelayMs);
  }

  private defaultShouldRetry(error: any): boolean {
    // ÈáçËØï 5xx ÈîôËØØÂíåÁΩëÁªúÈîôËØØ
    if (error.status >= 500) return true;
    if (error.code === 'ECONNRESET' || error.code === 'ETIMEDOUT') return true;
    
    // 429 ÈôêÊµÅ‰πüÈáçËØï
    if (error.status === 429) return true;
    
    return false;
  }

  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}

// ‰ΩøÁî®Á§∫‰æã
const retryHandler = new RetryHandler({
  maxAttempts: 3,
  baseDelayMs: 1000,
  maxDelayMs: 10000,
  backoffMultiplier: 2
});

await retryHandler.execute(async () => {
  return fetch(upstreamUrl, requestOptions);
});
```

### ÁõëÊéß‰∏éÊó•Âøó

```typescript
// src/lib/metrics.ts
export class MetricsCollector {
  private counters = new Map<string, number>();
  private histograms = new Map<string, number[]>();

  incrementCounter(name: string, value: number = 1): void {
    const current = this.counters.get(name) || 0;
    this.counters.set(name, current + value);
  }

  recordDuration(name: string, duration: number): void {
    const values = this.histograms.get(name) || [];
    values.push(duration);
    this.histograms.set(name, values);
  }

  getSnapshot(): MetricsSnapshot {
    const snapshot: MetricsSnapshot = {
      counters: Object.fromEntries(this.counters),
      histograms: {}
    };

    for (const [name, values] of this.histograms) {
      snapshot.histograms[name] = {
        count: values.length,
        sum: values.reduce((a, b) => a + b, 0),
        min: Math.min(...values),
        max: Math.max(...values),
        avg: values.reduce((a, b) => a + b, 0) / values.length,
        p95: this.percentile(values, 0.95),
        p99: this.percentile(values, 0.99)
      };
    }

    return snapshot;
  }

  private percentile(values: number[], p: number): number {
    const sorted = [...values].sort((a, b) => a - b);
    const index = Math.ceil(sorted.length * p) - 1;
    return sorted[index];
  }
}

// ‰∏≠Èó¥‰ª∂ÈõÜÊàê
export function metricsMiddleware(metrics: MetricsCollector) {
  return (req: Request, res: Response, next: Function) => {
    const startTime = Date.now();

    res.on('finish', () => {
      const duration = Date.now() - startTime;
      
      metrics.incrementCounter('http_requests_total');
      metrics.incrementCounter(`http_requests_${res.statusCode}`);
      metrics.recordDuration('http_request_duration_ms', duration);
    });

    next();
  };
}
```

### ÂÅ•Â∫∑Ê£ÄÊü•

```typescript
// src/routes/health.ts
import { Router } from 'express';

const router = Router();

router.get('/', async (req, res) => {
  const config = req.app.get('config');
  
  try {
    // Ê£ÄÊü•‰∏äÊ∏∏ËøûÊé•
    const upstreamHealth = await checkUpstreamHealth(config.upstream);
    
    // Ê£ÄÊü•Á≥ªÁªüËµÑÊ∫ê
    const systemHealth = checkSystemHealth();
    
    const health = {
      status: 'healthy',
      timestamp: new Date().toISOString(),
      version: process.env.npm_package_version || 'unknown',
      uptime: process.uptime(),
      upstream: upstreamHealth,
      system: systemHealth
    };

    res.json(health);
  } catch (error) {
    res.status(503).json({
      status: 'unhealthy',
      timestamp: new Date().toISOString(),
      error: error.message
    });
  }
});

router.get('/ready', async (req, res) => {
  // Â∞±Áª™Êé¢ÈíàÔºöÊ£ÄÊü•ÊúçÂä°ÊòØÂê¶ÂáÜÂ§áÂ•ΩÊé•ÂèóËØ∑Ê±Ç
  try {
    const config = req.app.get('config');
    await checkUpstreamHealth(config.upstream);
    res.status(200).json({ status: 'ready' });
  } catch (error) {
    res.status(503).json({ status: 'not ready', error: error.message });
  }
});

router.get('/live', (req, res) => {
  // Â≠òÊ¥ªÊé¢ÈíàÔºöÊ£ÄÊü•ÊúçÂä°ÊòØÂê¶ËøòÊ¥ªÁùÄ
  res.status(200).json({ status: 'alive' });
});

async function checkUpstreamHealth(upstreamConfig: any): Promise<any> {
  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), 5000);

  try {
    const response = await fetch(
      new URL('/models', upstreamConfig.baseUrl),
      {
        method: 'GET',
        headers: upstreamConfig.apiKey ? {
          'Authorization': `Bearer ${upstreamConfig.apiKey}`
        } : {},
        signal: controller.signal
      }
    );

    return {
      status: response.ok ? 'healthy' : 'degraded',
      statusCode: response.status,
      responseTime: Date.now() - Date.now() // ÁÆÄÂåñÁâà
    };
  } finally {
    clearTimeout(timeoutId);
  }
}

function checkSystemHealth() {
  const memUsage = process.memoryUsage();
  
  return {
    memory: {
      used: Math.round(memUsage.heapUsed / 1024 / 1024),
      total: Math.round(memUsage.heapTotal / 1024 / 1024),
      external: Math.round(memUsage.external / 1024 / 1024)
    },
    cpu: process.cpuUsage(),
    eventLoop: {
      // ÁÆÄÂåñÁöÑ‰∫ã‰ª∂Âæ™ÁéØÂª∂ËøüÊ£ÄÊµã
      lag: 0 // ÂÆûÈôÖÂÆûÁé∞ÈúÄË¶ÅÊõ¥Â§çÊùÇÁöÑÊ£ÄÊµã
    }
  };
}

export default router;
```

## ÈÉ®ÁΩ≤‰∏éËøêÁª¥

### Docker ÂåñÈÉ®ÁΩ≤

```dockerfile
# Dockerfile
FROM node:20-alpine AS builder

WORKDIR /app

# ÂÆâË£Ö‰æùËµñ
COPY package*.json ./
RUN npm ci --only=production

# ÊûÑÂª∫Â∫îÁî®
COPY . .
RUN npm run build

# Áîü‰∫ßÈïúÂÉè
FROM node:20-alpine AS runtime

# Èùû root Áî®Êà∑
RUN addgroup -g 1001 -S nodejs && \
    adduser -S proxy -u 1001

WORKDIR /app

# Â§çÂà∂ÊûÑÂª∫‰∫ßÁâ©
COPY --from=builder --chown=proxy:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=proxy:nodejs /app/dist ./dist
COPY --from=builder --chown=proxy:nodejs /app/package.json ./

USER proxy

EXPOSE 3000

# ÂÅ•Â∫∑Ê£ÄÊü•
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD node -e "fetch('http://localhost:3000/health').then(r=>r.ok?process.exit(0):process.exit(1))"

CMD ["node", "dist/server.js"]
```

### Docker Compose ÂºÄÂèëÁéØÂ¢É

```yaml
# docker-compose.yml
version: '3.8'

services:
  codex-proxy:
    build: .
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=development
      - LOG_LEVEL=debug
      - UPSTREAM_BASE_URL=http://mock-llm:8000/v1
      - UPSTREAM_SUPPORTS_RESPONSES=false
    depends_on:
      - mock-llm
    volumes:
      - ./config:/app/config:ro

  mock-llm:
    image: mock-server:latest
    ports:
      - "8000:8000"
    volumes:
      - ./test/fixtures:/app/fixtures:ro

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
```

### Kubernetes ÈÉ®ÁΩ≤

```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: codex-proxy
spec:
  replicas: 3
  selector:
    matchLabels:
      app: codex-proxy
  template:
    metadata:
      labels:
        app: codex-proxy
    spec:
      containers:
      - name: proxy
        image: codex-proxy:latest
        ports:
        - containerPort: 3000
        env:
        - name: NODE_ENV
          value: "production"
        - name: UPSTREAM_BASE_URL
          valueFrom:
            secretKeyRef:
              name: codex-config
              key: upstream-url
        - name: UPSTREAM_API_KEY
          valueFrom:
            secretKeyRef:
              name: codex-config
              key: api-key
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health/live
            port: 3000
          initialDelaySeconds: 10
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /health/ready
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 10

---
apiVersion: v1
kind: Service
metadata:
  name: codex-proxy-service
spec:
  selector:
    app: codex-proxy
  ports:
  - protocol: TCP
    port: 80
    targetPort: 3000
  type: LoadBalancer
```

### ÁõëÊéßÈÖçÁΩÆ

```yaml
# monitoring/prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'codex-proxy'
    static_configs:
      - targets: ['codex-proxy:3000']
    metrics_path: '/metrics'
    scrape_interval: 5s

  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']
```

## ÊÄßËÉΩ‰ºòÂåñ

### ËøûÊé•Ê±†‰ºòÂåñ

```typescript
// src/lib/http-client.ts
import { Agent } from 'undici';

export class OptimizedHttpClient {
  private agent: Agent;

  constructor() {
    this.agent = new Agent({
      keepAliveTimeout: 30000,
      keepAliveMaxTimeout: 600000,
      maxRedirections: 3,
      connect: {
        timeout: 10000,
        keepAlive: true
      }
    });
  }

  async fetch(url: string | URL, options: any = {}): Promise<Response> {
    return fetch(url, {
      ...options,
      dispatcher: this.agent
    });
  }

  destroy(): void {
    this.agent.close();
  }
}
```

### ÁºìÂ≠òÁ≠ñÁï•

```typescript
// src/lib/cache.ts
export interface CacheEntry<T> {
  value: T;
  expiresAt: number;
}

export class MemoryCache<T> {
  private cache = new Map<string, CacheEntry<T>>();
  private maxSize: number;

  constructor(maxSize: number = 1000) {
    this.maxSize = maxSize;
  }

  set(key: string, value: T, ttlMs: number): void {
    // LRU Ê∏ÖÁêÜ
    if (this.cache.size >= this.maxSize) {
      const firstKey = this.cache.keys().next().value;
      this.cache.delete(firstKey);
    }

    this.cache.set(key, {
      value,
      expiresAt: Date.now() + ttlMs
    });
  }

  get(key: string): T | null {
    const entry = this.cache.get(key);
    if (!entry) return null;

    if (entry.expiresAt < Date.now()) {
      this.cache.delete(key);
      return null;
    }

    return entry.value;
  }

  clear(): void {
    this.cache.clear();
  }
}

// Ê®°ÂûãÂàóË°®ÁºìÂ≠òÁ§∫‰æã
const modelCache = new MemoryCache<any[]>();

export async function getCachedModels(upstreamUrl: string): Promise<any[]> {
  const cacheKey = `models:${upstreamUrl}`;
  
  let models = modelCache.get(cacheKey);
  if (models) return models;

  // ‰ªé‰∏äÊ∏∏Ëé∑Âèñ
  const response = await fetch(new URL('/models', upstreamUrl));
  models = await response.json();
  
  // ÁºìÂ≠ò 5 ÂàÜÈíü
  modelCache.set(cacheKey, models, 5 * 60 * 1000);
  
  return models;
}
```

---

## ‰∏ã‰∏ÄÊ≠•
- **[ÊµãËØïÈ™åËØÅ](./06-testing-validation.md)**ÔºöÈ™åËØÅ‰ª£ÁêÜÂÆûÁé∞ÁöÑÊ≠£Á°ÆÊÄß
- **[Â∑•ÂÖ∑ÈõÜÊàê](./04-tools-integration.md)**Ôºö‰∏∫‰ª£ÁêÜÊ∑ªÂä†Â∑•ÂÖ∑ÊîØÊåÅ
- **[ÈÖçÁΩÆÊåáÂçó](./03-configuration-guide.md)**Ôºö‰ºòÂåñ Codex ÈÖçÁΩÆ

Ëøô‰ªΩÂÆûÁé∞ÊåáÂçóÊèê‰æõ‰∫ÜÊûÑÂª∫Áîü‰∫ßÁ∫ß Node.js ‰ª£ÁêÜÁöÑÂÆåÊï¥ÊñπÊ°àÔºåÊ∂µÁõñ‰∫Ü‰ªéÂü∫Á°ÄÂäüËÉΩÂà∞È´òÁ∫ßÁâπÊÄßÁöÑÂêÑ‰∏™ÊñπÈù¢„ÄÇÈÄöËøáËøô‰∏™ÂÆûÁé∞Ôºå‰Ω†ÂèØ‰ª•‰∏∫ Codex ÊûÑÂª∫ÂèØÈù†„ÄÅÈ´òÊÄßËÉΩÁöÑ LLM ‰ª£ÁêÜÊúçÂä°„ÄÇ